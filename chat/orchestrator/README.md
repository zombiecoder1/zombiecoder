# Prompt Orchestration System

**Editor à¦­à¦¾à¦‡-à¦à¦° à¦œà¦¨à§à¦¯ Smart Prompt Routing System**

à¦à¦•à¦Ÿà¦¿ à¦¸à¦®à§à¦ªà§‚à¦°à§à¦£ AI-powered prompt orchestration system à¦¯à¦¾ user input à¦•à§‡ intelligently process à¦•à¦°à§‡, appropriate AI models à¦ route à¦•à¦°à§‡, à¦à¦¬à¦‚ multiple formats à¦ response à¦¦à§‡à¦¯à¦¼à¥¤

## ğŸš€ Features

- **Smart Input Processing**: Multi-language input detection à¦à¦¬à¦‚ normalization
- **Intelligent Prompt Refining**: Context-aware prompt enhancement
- **Model Routing**: Automatic routing to appropriate AI models
- **Multi-format Output**: JSON, HTML, Text, Audio, Code, Conversation formats
- **Real-time TTS**: Bengali à¦à¦¬à¦‚ English text-to-speech support
- **Conversation History**: Session-based conversation tracking
- **Health Monitoring**: Comprehensive system health checks

## ğŸ“ Project Structure

```
prompt_orchestration_system/
â”œâ”€â”€ config.py              # System configuration
â”œâ”€â”€ input_handler.py       # User input processing
â”œâ”€â”€ prompt_refiner.py      # Prompt refinement and routing
â”œâ”€â”€ model_interface.py     # AI model integration
â”œâ”€â”€ output_formatter.py    # Multi-format response formatting
â”œâ”€â”€ main_orchestrator.py   # Main orchestration system
â”œâ”€â”€ api_server.py          # FastAPI web server
â”œâ”€â”€ demo.py               # Interactive demo script
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md            # This file
```

## ğŸ› ï¸ Installation

1. **Clone or download the project**
2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure models** (optional):
   - Edit `config.py` to add your API keys
   - Configure local model endpoints

## ğŸ¯ Usage

### 1. Interactive Demo
```bash
python demo.py
```

### 2. Web API Server
```bash
python api_server.py
```
Then visit: `http://localhost:8000`

### 3. Direct Usage
```python
from main_orchestrator import PromptOrchestrator

orchestrator = PromptOrchestrator()
response = orchestrator.process_request(
    user_input="à¦†à¦œà¦•à§‡à¦° à¦†à¦¬à¦¹à¦¾à¦“à¦¯à¦¼à¦¾ à¦•à§‡à¦®à¦¨?",
    output_format="json"
)
```

## ğŸ“¡ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | System information and documentation |
| `/process` | POST | Process user input and get AI response |
| `/status` | GET | Get comprehensive system status |
| `/health` | GET | Health check endpoint |
| `/history` | GET | Get conversation history |
| `/stats` | GET | Get system statistics |
| `/reset` | POST | Reset current session |
| `/formats` | GET | Get supported output formats |

## ğŸ”§ Configuration

### Model Configuration
Edit `config.py` to configure your AI models:

```python
models = {
    "llm_local": ModelConfig(
        name="Local LLM",
        endpoint="http://localhost:11434/api/generate",
        model_type="llm"
    ),
    "tts_coqui": ModelConfig(
        name="Coqui TTS",
        endpoint="local",
        model_type="tts"
    )
}
```

### Supported Languages
- Bengali (à¦¬à¦¾à¦‚à¦²à¦¾)
- English
- Hindi
- Urdu
- Arabic

### Output Formats
- **JSON**: Structured data response
- **HTML**: Web-formatted response
- **Text**: Plain text response
- **Audio**: TTS audio response
- **Code**: Code-formatted response
- **Conversation**: Conversational response

## ğŸ¨ Example Usage

### Bengali Weather Query
```python
response = orchestrator.process_request(
    user_input="à¦†à¦œà¦•à§‡à¦° à¦†à¦¬à¦¹à¦¾à¦“à¦¯à¦¼à¦¾ à¦•à§‡à¦®à¦¨?",
    output_format="json"
)
```

### English Coding Help
```python
response = orchestrator.process_request(
    user_input="How to fix a Python bug?",
    output_format="code"
)
```

### Translation Request
```python
response = orchestrator.process_request(
    user_input="Translate this to English: 'à¦†à¦®à¦¿ à¦à¦•à¦œà¦¨ à¦ªà§à¦°à§‹à¦—à§à¦°à¦¾à¦®à¦¾à¦°'",
    output_format="html"
)
```

## ğŸ” System Components

### 1. Input Handler
- Language detection
- Text normalization
- Intent extraction
- Confidence scoring

### 2. Prompt Refiner
- Template selection
- Context enhancement
- Model routing
- Parameter optimization

### 3. Model Interface
- LLM integration (Ollama, OpenAI)
- TTS integration (Coqui TTS)
- Error handling
- Fallback mechanisms

### 4. Output Formatter
- Multi-format support
- Code highlighting
- Audio generation
- Response structuring

## ğŸ“Š Monitoring

### Health Check
```bash
curl http://localhost:8000/health
```

### System Status
```bash
curl http://localhost:8000/status
```

### Statistics
```bash
curl http://localhost:8000/stats
```

## ğŸš¨ Error Handling

The system includes comprehensive error handling:
- Input validation
- Model fallbacks
- Graceful degradation
- Detailed error logging

## ğŸ”§ Development

### Running Tests
```bash
python -m pytest tests/
```

### Code Formatting
```bash
black .
flake8 .
```

### Adding New Models
1. Add model configuration to `config.py`
2. Implement query method in `model_interface.py`
3. Update routing logic in `prompt_refiner.py`

## ğŸ“ Logging

The system logs all activities:
- Request processing
- Model queries
- Error conditions
- Performance metrics

Logs are written to:
- Console output
- `orchestration.log` file

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is part of the ZombieCoder Agent System.

## ğŸ‘¨â€ğŸ’» Author

**à¦¸à¦¾à¦¹à¦¨ à¦­à¦¾à¦‡** - ZombieCoder Agent System

---

## ğŸ¯ Quick Start

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Run the demo**:
   ```bash
   python demo.py
   ```

3. **Start the API server**:
   ```bash
   python api_server.py
   ```

4. **Visit the web interface**:
   Open `http://localhost:8000` in your browser

## ğŸ’¡ Tips

- Start with the interactive demo to understand the system
- Use Bengali and English inputs for best results
- Check system status regularly for optimal performance
- Monitor logs for debugging and optimization

**Happy coding with Editor à¦­à¦¾à¦‡! ğŸš€**
