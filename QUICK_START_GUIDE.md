# ğŸš€ ZombieCoder Local AI Quick Start Guide

> **Complete Local AI Setup for Cursor, VS Code, and Terminal**

## ğŸ¯ What You'll Get

- **ğŸ§  Local AI Models** (Ollama + Llama)
- **ğŸ”Œ OpenAI API Compatible** (Port 8001)
- **ğŸ§Ÿâ€â™‚ï¸ Advanced AI Agents** (Port 12345)
- **ğŸ“± Editor Integration** (Cursor, VS Code, Terminal)
- **âš¡ Zero Cloud Dependency** (100% Local)

## ğŸš€ One-Click Setup

### Step 1: Run GLOBAL_LAUNCHER.bat
```bash
# Double-click or run in terminal
GLOBAL_LAUNCHER.bat
```

**What it does automatically:**
- ğŸ§¹ Cleans up blocked ports
- ğŸ”§ Sets environment variables
- ğŸ“ Creates configuration files
- ğŸš€ Starts all services
- ğŸ§ª Tests all APIs
- âœ… Configures editors

### Step 2: Wait for Completion
```
====================================================
   ğŸ§Ÿâ€â™‚ï¸ ZombieCoder Local AI System Starting...
====================================================

[1/5] ğŸ§¹ Cleaning up blocked ports and processes...
[2/5] ğŸ¤– Starting Ollama Models...
[3/5] ğŸ”Œ Starting OpenAI Shim Server...
[4/5] ğŸ§Ÿâ€â™‚ï¸ Starting ZombieCoder Agent System...
[5/5] ğŸ”„ Starting Additional Services...

ğŸ¯ All services started! Checking status...
ğŸ“Š Checking Service Status...
âœ… Ollama: http://127.0.0.1:11434 - RUNNING
âœ… OpenAI Shim: http://127.0.0.1:8001 - RUNNING
âœ… ZombieCoder: http://127.0.0.1:12345 - RUNNING
```

## ğŸ“± Editor Integration

### ğŸ¨ Cursor AI
1. **Automatic Setup** âœ… (via GLOBAL_LAUNCHER.bat)
2. **Test**: Press `Ctrl+Shift+I`
3. **Configuration**: `.env` file auto-created

### ğŸ”§ VS Code
1. **Automatic Setup** âœ… (via GLOBAL_LAUNCHER.bat)
2. **Test**: `Ctrl+Shift+P` â†’ ZombieCoder
3. **Configuration**: `.vscode/settings.json` auto-created

### ğŸ’» Terminal
1. **Test Local AI**:
```bash
curl http://127.0.0.1:8001/health
```

2. **Test AI Chat**:
```bash
curl -X POST http://127.0.0.1:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"local-llama","messages":[{"role":"user","content":"Hello"}]}'
```

## ğŸ” Verification

### Check All Services
```bash
# Port Status
netstat -an | findstr ":8001\|:12345\|:11434"

# Service Health
curl http://127.0.0.1:8001/health
curl http://127.0.0.1:12345/
curl http://127.0.0.1:11434/api/tags
```

### Check Configuration Files
```bash
# Environment Files
dir /s .env

# VS Code Settings
type .vscode\settings.json

# Cursor Rules
type .cursorrules
```

## ğŸš¨ Troubleshooting

### Port Already in Use
```bash
# Kill processes on ports
for /f "tokens=5" %%a in ('netstat -aon ^| findstr ":8001"') do taskkill /PID %%a /F
for /f "tokens=5" %%a in ('netstat -aon ^| findstr ":12345"') do taskkill /PID %%a /F
for /f "tokens=5" %%a in ('netstat -aon ^| findstr ":11434"') do taskkill /PID %%a /F
```

### Service Not Starting
```bash
# Check Python installation
python --version

# Check Ollama installation
ollama --version

# Check logs
dir core-server\logs
```

### Editor Not Working
```bash
# Restart editor after setup
# Verify .env file exists
# Check environment variables
echo %OPENAI_API_BASE%
```

## ğŸ“‹ Configuration Files Created

### .env (Root Directory)
```bash
OPENAI_API_BASE=http://127.0.0.1:8001/v1
OPENAI_API_KEY=local-ai-key
FORCE_LOCAL_AI=true
LOCAL_AI_ENDPOINT=http://127.0.0.1:8001/v1
ZOMBIECODER_HOST=http://127.0.0.1:12345
OLLAMA_HOST=http://127.0.0.1:11434
```

### .vscode/settings.json
```json
{
  "openai.apiBase": "http://127.0.0.1:8001/v1",
  "openai.apiKey": "local-ai-key",
  "openai.forceLocal": true,
  "zombiecoder.endpoint": "http://127.0.0.1:8001/v1",
  "zombiecoder.apiKey": "local-ai-key"
}
```

### .cursorrules
```bash
# Cursor AI Local Configuration
FORCE_LOCAL_AI=true
LOCAL_AI_ENDPOINT=http://127.0.0.1:8001/v1
LOCAL_AI_KEY=local-ai-key
AI_MODEL=local-llama
AI_PROVIDER=zombiecoder
```

## ğŸ‰ Success Indicators

### âœ… All Services Running
- Ollama: Port 11434 âœ…
- OpenAI Shim: Port 8001 âœ…
- ZombieCoder: Port 12345 âœ…
- Proxy: Port 8080 âœ…
- Multi-Project API: Port 8081 âœ…

### âœ… Editor Integration
- Cursor AI: Local AI working âœ…
- VS Code: ZombieCoder extension ready âœ…
- Terminal: curl commands working âœ…

### âœ… Configuration
- Environment variables set âœ…
- .env files created âœ…
- VS Code settings configured âœ…
- Cursor rules applied âœ…

## ğŸ”„ Daily Usage

### Start System
```bash
GLOBAL_LAUNCHER.bat
```

### Stop System
```bash
# Kill all processes
taskkill /F /IM python.exe
taskkill /F /IM ollama.exe
```

### Check Status
```bash
# Quick status check
curl http://127.0.0.1:8001/health
```

## ğŸ†˜ Need Help?

1. **Check this guide** ğŸ“–
2. **Run GLOBAL_LAUNCHER.bat** ğŸš€
3. **Check troubleshooting section** ğŸ”
4. **Verify configuration files** ğŸ“

---

**ğŸ¯ Your Local AI System is Ready!**

- **No more cloud dependency** â˜ï¸â¡ï¸ğŸ 
- **Faster response times** âš¡
- **Complete privacy** ğŸ”’
- **Advanced AI agents** ğŸ¤–
- **Editor integration** ğŸ“±
