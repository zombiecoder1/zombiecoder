# ğŸ¤– Shaon AI Advanced System v3.0

> **"à¦¯à§‡à¦–à¦¾à¦¨à§‡ à¦•à§‹à¦¡ à¦“ à¦•à¦¥à¦¾ à¦¬à¦²à§‡, à¦ªà¦°à¦¿à¦¬à¦¾à¦°à§‡à¦° à¦®à¦¤ à¦¸à¦¹à¦¾à¦¯à¦¼à¦¤à¦¾ à¦•à¦°à§‡"**

[![Version](https://img.shields.io/badge/version-3.0.0-blue.svg)](https://github.com/devsahon/ZombieCoder-Agent-Personal)
[![Branch](https://img.shields.io/badge/branch-alhamdullha--advanced--system-green.svg)](https://github.com/devsahon/ZombieCoder-Agent-Personal/tree/alhamdullha-advanced-system)
[![Python](https://img.shields.io/badge/python-3.11+-yellow.svg)](https://python.org)
[![Node.js](https://img.shields.io/badge/node.js-18+-green.svg)](https://nodejs.org)

## ğŸ¯ Overview

**Shaon AI Advanced System v3.0** is a comprehensive local AI-powered development assistant that combines multiple AI agents with advanced features like Lazy Loading, Memory Management, Smart Routing, and VSCode integration.

### ğŸŒŸ Key Features

- **ğŸ¤– 5 AI Agents** with unique personalities and 10 capabilities each
- **âš¡ Lazy Loading** for optimal performance
- **ğŸ’¾ Memory Management** with automatic cleanup
- **ğŸ§  Smart Routing** with cloud fallback
- **ğŸ”Œ VSCode Extension** with Copilot integration
- **ğŸ“Š Multi-Project API** support
- **ğŸ“ˆ Real-time Status Monitoring**

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Shaon AI Advanced System                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   VSCode    â”‚  â”‚   Browser   â”‚  â”‚   Terminal  â”‚         â”‚
â”‚  â”‚ Extension   â”‚  â”‚   Interface â”‚  â”‚   Commands  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Proxy Server (Port 8080)                â”‚
â”‚                    Smart Routing & Load Balancing           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Advanced   â”‚  â”‚   Multi-    â”‚  â”‚   Cloud     â”‚         â”‚
â”‚  â”‚   Agent     â”‚  â”‚  Project    â”‚  â”‚  Fallback   â”‚         â”‚
â”‚  â”‚  System     â”‚  â”‚    API      â”‚  â”‚  Providers  â”‚         â”‚
â”‚  â”‚ (Port 12345)â”‚  â”‚(Port 8081)  â”‚  â”‚             â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Local AI (Ollama)                       â”‚
â”‚                    Models: llama3.2:1b, qwen2.5-coder, etc.â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤– AI Agents

### ğŸ‘¨â€ğŸ’» à¦¸à¦¾à¦¹à¦¨ à¦­à¦¾à¦‡ (Elder Brother)
- **Role**: Technical advisor and mentor
- **Expertise**: Coding, debugging, system architecture
- **Capabilities**: Code review, performance optimization, security audit

### ğŸ‘§ à¦®à§à¦¸à¦•à¦¾à¦¨ (Creative Specialist)
- **Role**: Frontend and creative development
- **Expertise**: UI/UX, frontend development, creative coding
- **Capabilities**: Responsive design, animations, modern frameworks

### ğŸ‘©â€ğŸ’¼ à¦­à¦¾à¦¬à¦¿ (Backend Specialist)
- **Role**: Backend and database management
- **Expertise**: Database design, API development, security
- **Capabilities**: Data modeling, microservices, system integration

### ğŸ¯ à¦¬à¦¾à¦˜ (Security Specialist)
- **Role**: Security and performance optimization
- **Expertise**: Security audit, penetration testing, system hardening
- **Capabilities**: Threat hunting, cryptography, incident response

### ğŸ” à¦¹à¦¾à¦¨à§à¦Ÿà¦¾à¦° (Quality Specialist)
- **Role**: Quality assurance and debugging
- **Expertise**: Bug hunting, code review, quality assurance
- **Capabilities**: Automated testing, performance profiling, code analysis

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Node.js 18+
- Ollama (with models: `llama3.2:1b`, `qwen2.5-coder:1.5b-base`)

### Installation

```bash
# 1. Clone repository
git clone https://github.com/devsahon/ZombieCoder-Agent-Personal.git
cd ZombieCoder-Agent-Personal

# 2. Switch to advanced branch
git checkout alhamdullha-advanced-system

# 3. Install dependencies
pip install -r config/requirements.txt
cd shaon-extension && npm install

# 4. Start system
./GLOBAL_LAUNCHER.bat
```

### Manual Setup

```bash
# Start Advanced Agent System
python core-server/advanced_agent_system.py

# Start Proxy Server
python optimized_port_routing.py

# Start Multi-Project API
python our-server/multi_project_api.py
```

## ğŸ“– Usage

### Terminal Usage
```bash
# Chat with specific agent
curl -X POST http://localhost:12345/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Create a Python function", "agent": "à¦¸à¦¾à¦¹à¦¨ à¦­à¦¾à¦‡"}'

# Check system status
curl http://localhost:12345/status
```

### Browser Usage
- **Advanced Agent System**: http://localhost:12345
- **Proxy Server**: http://localhost:8080
- **Multi-Project API**: http://localhost:8081

### VSCode Usage
1. Install extension: `code --install-extension shaon-zombiecoder-extension-1.0.0.vsix`
2. Press `Ctrl+Shift+P`
3. Type "Shaon: Copilot Chat"
4. Select agent and start chatting

## ğŸ”Œ API Reference

### Advanced Agent System (Port 12345)

#### POST `/chat`
Chat with AI agents
```json
{
  "message": "Your message here",
  "agent": "à¦¸à¦¾à¦¹à¦¨ à¦­à¦¾à¦‡"
}
```

#### GET `/status`
Get system status
```json
{
  "system": "ZombieCoder Advanced Agent System",
  "agents": {...},
  "system_status": {...},
  "memory_stats": {...}
}
```

#### GET `/info`
Get system information
```json
{
  "name": "ZombieCoder Advanced Agent System",
  "version": "3.0.0",
  "features": [...],
  "agents": [...]
}
```

## ğŸ§  Smart Features

### Lazy Loading
- Agent personalities load only when needed
- Reduces memory usage and startup time
- Automatic performance optimization

### Memory Management
- Automatic cleanup every 5 minutes
- History management (last 100 conversations)
- Cache management (maximum 50 entries)
- Real-time performance monitoring

### Smart Routing
- Complex prompt detection
- Automatic cloud fallback
- Intelligent provider selection
- Performance-based routing

## ğŸ”§ Configuration

### Environment Setup
```bash
# Install Ollama models
ollama pull llama3.2:1b
ollama pull qwen2.5-coder:1.5b-base
ollama pull codellama:latest
ollama pull llama3.1:8b
```

### API Keys (Optional)
Edit `our-server/config.json`:
```json
{
  "cloud_fallback": {
    "api_keys": {
      "openrouter": "your_openrouter_key",
      "together": "your_together_key",
      "huggingface": "your_huggingface_key",
      "anthropic": "your_anthropic_key"
    }
  }
}
```

## ğŸ“Š Monitoring

### Real-time Status
```bash
# Monitor system status
watch -n 5 'curl -s http://localhost:12345/status | jq'

# Monitor memory usage
watch -n 10 'curl -s http://localhost:12345/status | jq .memory_stats'
```

### Log Files
- **Advanced Agent System**: `core-server/logs/`
- **Proxy Server**: `proxy-server/logs/`
- **Multi-Project API**: `our-server/logs/`

## ğŸ”§ Troubleshooting

### Common Issues

#### Ollama Connection Error
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama if not running
ollama serve
```

#### Port Already in Use
```bash
# Find process using port
netstat -ano | findstr :12345

# Kill process
taskkill /PID <PID> /F
```

#### VSCode Extension Not Working
```bash
# Rebuild extension
cd shaon-extension
npm run build:extension

# Reinstall extension
code --install-extension shaon-zombiecoder-extension-1.0.0.vsix
```

## ğŸ“ Project Structure

```
D:\Alhamdullha\
â”œâ”€â”€ core-server/
â”‚   â”œâ”€â”€ advanced_agent_system.py    # Main AI system
â”‚   â”œâ”€â”€ memory_manager.py           # Memory management
â”‚   â””â”€â”€ agents/                     # Agent personalities
â”œâ”€â”€ our-server/
â”‚   â”œâ”€â”€ ai_providers.py             # Cloud fallback providers
â”‚   â”œâ”€â”€ multi_project_api.py        # Multi-project API
â”‚   â””â”€â”€ config.json                 # Configuration
â”œâ”€â”€ shaon-extension/
â”‚   â”œâ”€â”€ src/                        # VSCode extension source
â”‚   â”œâ”€â”€ dist/                       # Compiled extension
â”‚   â””â”€â”€ package.json                # Extension configuration
â”œâ”€â”€ optimized_port_routing.py       # Proxy server
â”œâ”€â”€ GLOBAL_LAUNCHER.bat             # System launcher
â”œâ”€â”€ power-switch.bat                # Power management
â””â”€â”€ SYSTEM_DOCUMENTATION.md         # Complete documentation
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -am 'Add feature'`
4. Push to branch: `git push origin feature-name`
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Ollama** for local AI models
- **VSCode** for extension platform
- **Flask** for web framework
- **Next.js** for extension UI

## ğŸ“ Support

- **Repository**: https://github.com/devsahon/ZombieCoder-Agent-Personal
- **Branch**: `alhamdullha-advanced-system`
- **Documentation**: [SYSTEM_DOCUMENTATION.md](SYSTEM_DOCUMENTATION.md)

---

## ğŸ‰ Features Summary

| Feature | Status | Description |
|---------|--------|-------------|
| ğŸ¤– 5 AI Agents | âœ… | Unique personalities with 10 capabilities each |
| âš¡ Lazy Loading | âœ… | Performance optimization |
| ğŸ’¾ Memory Management | âœ… | Automatic cleanup and monitoring |
| ğŸ§  Smart Routing | âœ… | Complex prompt detection and cloud fallback |
| ğŸ”Œ VSCode Extension | âœ… | Copilot-style integration |
| ğŸ“Š Multi-Project API | âœ… | Project management and tracking |
| ğŸŒ Cloud Fallback | âœ… | Multiple provider support |
| ğŸ“ˆ Real-time Monitoring | âœ… | Status and performance tracking |

---

*Last Updated: August 24, 2025*  
*Version: 3.0.0*  
*Branch: alhamdullha-advanced-system*
