# ЁЯзЯтАНтЩВя╕П Zombie Family - рж╕ржорж╕рзНржпрж╛ рж╕ржорж╛ржзрж╛ржи

## ЁЯФН рж╕ржорж╕рзНржпрж╛ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг

ржЖржкржирж╛рж░ Zombie Family рж╕рж┐рж╕рзНржЯрзЗржорзЗ ржжрзБржЯрж┐ ржорзВрж▓ рж╕ржорж╕рзНржпрж╛ ржЫрж┐рж▓:

### рзз. OpenRouter Model ID ржнрзБрж▓
```
OpenRouter error: 400 - {"error":{"message":"claude-3.5-sonnet is not a valid model ID","code":400}}
```

**ржХрж╛рж░ржг:** OpenRouter ржП model ID ржПрж░ format ржнрж┐ржирзНржиред рж╕ржарж┐ржХ format: `anthropic/claude-3.5-sonnet`

### рзи. Ollama Server Connection Timeout
```
Local AI error: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=15)
```

**ржХрж╛рж░ржг:** Ollama server offline ржЫрж┐рж▓ ржмрж╛ response ржжрж┐рждрзЗ ржжрзЗрж░рж┐ ржХрж░ржЫрж┐рж▓ред

## тЬЕ рж╕ржорж╛ржзрж╛ржи

### рзз. OpenRouter Model ID ржарж┐ржХ ржХрж░рж╛

**ржлрж╛ржЗрж▓:** `our-server/ai_providers.py`

**ржкрж░рж┐ржмрж░рзНрждржи:**
```python
# ржЖржЧрзЗ
'models': ['claude-3.5-sonnet', 'llama-3.1-8b-instruct', 'gpt-4o-mini']

# ржкрж░рзЗ  
'models': ['anthropic/claude-3.5-sonnet', 'meta-llama/llama-3.1-8b-instruct', 'openai/gpt-4o-mini']
```

**ржлрж╛ржЗрж▓:** `test_cloud_fallback.py`
```python
# ржЖржЧрзЗ
'model': 'claude-3.5-sonnet',

# ржкрж░рзЗ
'model': 'anthropic/claude-3.5-sonnet',
```

### рзи. Ollama Server Status

тЬЕ **Ollama server ржЪрж╛рж▓рзБ ржЖржЫрзЗ** - port 11434 ржП running

### рзй. OpenRouter API Key ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи

**ржлрж╛ржЗрж▓:** `our-server/config.json`
```json
{
  "cloud_fallback": {
    "api_keys": {
      "openrouter": "YOUR_API_KEY_HERE"
    }
  }
}
```

## ЁЯЪА ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржирж┐рж░рзНржжрзЗрж╢ржирж╛

### рзз. OpenRouter API Key ржпрзЛржЧ ржХрж░рж╛
```bash
python quick_fix_openrouter.py
```

### рзи. рж╕рж┐рж╕рзНржЯрзЗржо ржЯрзЗрж╕рзНржЯ ржХрж░рж╛
```bash
python fix_zombie_family.py
```

### рзй. Ollama Server ржЪрзЗржХ ржХрж░рж╛
```bash
start_ollama.bat
```

### рзк. ржорзВрж▓ рж╕рж╛рж░рзНржнрж╛рж░ ржЪрж╛рж▓рзБ ржХрж░рж╛
```bash
python our-server/unified_agent_system.py
```

## ЁЯУЛ рж╕ржарж┐ржХ Model IDs

### OpenRouter Models
- `anthropic/claude-3.5-sonnet` тЬЕ
- `anthropic/claude-3-haiku` тЬЕ
- `meta-llama/llama-3.1-8b-instruct` тЬЕ
- `openai/gpt-4o-mini` тЬЕ
- `openai/gpt-3.5-turbo` тЬЕ

### Ollama Models
- `llama3.2:1b` тЬЕ
- `qwen2.5-coder:1.5b-base` тЬЕ
- `codellama:latest` тЬЕ

## ЁЯФз ржкрж░ржмрж░рзНрждрзА ржкржжржХрзНрж╖рзЗржк

1. **OpenRouter API Key ржпрзЛржЧ ржХрж░рзБржи:**
   - https://openrouter.ai ржП ржпрж╛ржи
   - Sign up/Login ржХрж░рзБржи
   - API Keys section ржП ржпрж╛ржи
   - ржирждрзБржи API key рждрзИрж░рж┐ ржХрж░рзБржи
   - `quick_fix_openrouter.py` ржЪрж╛рж▓рзБ ржХрж░рзЗ key ржпрзЛржЧ ржХрж░рзБржи

2. **рж╕рж┐рж╕рзНржЯрзЗржо ржЯрзЗрж╕рзНржЯ ржХрж░рзБржи:**
   ```bash
   python fix_zombie_family.py
   ```

3. **рж╕рж╛рж░рзНржнрж╛рж░ ржЪрж╛рж▓рзБ ржХрж░рзБржи:**
   ```bash
   python our-server/unified_agent_system.py
   ```

4. **ржмрзНрж░рж╛ржЙржЬрж╛рж░рзЗ ржЪрзЗржХ ржХрж░рзБржи:**
   - http://localhost:12345

## ЁЯУК ржмрж░рзНрждржорж╛ржи рж╕рзНржЯрзНржпрж╛ржЯрж╛рж╕

- тЬЕ Ollama Server: Running (port 11434)
- тЬЕ Main Server: Running (port 12345)
- тЬЕ Proxy Server: Running (port 8080)
- тЬЕ Multi-Project API: Running (port 8081)
- тЪая╕П OpenRouter: API Key needed
- тЬЕ Local AI: Available

## ЁЯОп ржлрж▓рж╛ржлрж▓

ржПржЗ рж╕ржорж╛ржзрж╛ржиржЧрзБрж▓рж┐ ржкрзНрж░ржпрж╝рзЛржЧ ржХрж░рж╛рж░ ржкрж░:
- OpenRouter error ржЖрж░ ржЖрж╕ржмрзЗ ржирж╛
- Local AI (Ollama) рж╕ржарж┐ржХржнрж╛ржмрзЗ ржХрж╛ржЬ ржХрж░ржмрзЗ
- Cloud fallback рж╕рж┐рж╕рзНржЯрзЗржо рж╕ржХрзНрж░рж┐ржпрж╝ ржерж╛ржХржмрзЗ
- Multi-project support ржХрж╛ржЬ ржХрж░ржмрзЗ

---

**ЁЯТб ржЯрж┐ржк:** ржпржжрж┐ ржХрзЛржи рж╕ржорж╕рзНржпрж╛ ржерж╛ржХрзЗ, `fix_zombie_family.py` script ржЪрж╛рж▓рзБ ржХрж░рзЗ diagnostic report ржжрзЗржЦрзБржиред
